{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Gaussian MoCo Unseen-Distribution Novelty Test\n",
    "\n",
    "A simple baseline novelty detector.\n",
    "* Problem: After seeing imagenet training set for 500 classes, determine if a new image is in a different class.\n",
    "* Solution: use a simple Gaussian models for each known class.  Score as the ratio of the probabilities (i.e., difference of log probabilities).\n",
    "* Performance: if novel/non-novel is 50% mix, average precision is 0.72.\n",
    "\n",
    "First, load imagenet moco model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from cmc.models.resnet import InsResNet50\n",
    "from torchvision import transforms\n",
    "from netdissect import tally, runningstats, renormalize, parallelfolder\n",
    "\n",
    "expdir = 'results/places-moco-multi-gaussian'\n",
    "def ef(s):\n",
    "    return os.path.join(expdir, s)\n",
    "\n",
    "dataset = \"imagenet\"\n",
    "model_dataset = \"places\"\n",
    "model_dir = \"/data/vision/torralba/dissect/novelty/models\"\n",
    "model_name = f\"{model_dataset}_moco_resnet50.pth\"\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "val_path = f\"datasets/{dataset}/val\"\n",
    "train_path = f\"datasets/{dataset}/train\"\n",
    "\n",
    "img_trans = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    renormalize.NORMALIZER['imagenet']\n",
    "])\n",
    "dsv = parallelfolder.ParallelImageFolders([val_path], transform=img_trans, classification=True)\n",
    "dst = parallelfolder.ParallelImageFolders([train_path], transform=img_trans, classification=True)\n",
    "dsm = dict(val=dsv, train=dst)\n",
    "dp_model = InsResNet50()\n",
    "checkpoint = torch.load(model_path)\n",
    "dp_model.load_state_dict(checkpoint['model_ema'])\n",
    "model = dp_model.encoder.module\n",
    "model.cuda()\n",
    "None                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: make a baseline Gaussian model over the whole imagenet distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layernum = 7\n",
    "\n",
    "def batch_features(imgbatch, cls):\n",
    "    result = model(imgbatch.cuda(), layer=layernum)\n",
    "    if len(result.shape) == 4:\n",
    "        result = result.permute(0, 2, 3, 1).reshape(-1, result.shape[1])\n",
    "    return result\n",
    "\n",
    "split = 'train'\n",
    "mcov = tally.tally_covariance(batch_features, dsm[split], num_workers=100, batch_size=512, pin_memory=True,\n",
    "                             cachefile=ef(f'{dataset}-{split}-layer{layernum}-mcov.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make 1000 \"selected class\" Gaussian models, grouping all observed classes in one giant gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_selclass_features(imgbatch, cls):\n",
    "    result = model(imgbatch.cuda(), layer=layernum)\n",
    "    if len(result.shape) == 4:\n",
    "        cls = cls[:,None,None].expand(result.shape[0],\n",
    "                result.shape[2], result.shape[3]).reshape(-1)\n",
    "        result = result.permute(0, 2, 3, 1).reshape(-1, result.shape[1])\n",
    "    return [(c.item(), result[cls == c]) for c in torch.unique(cls)]\n",
    "\n",
    "selcov = tally.tally_conditional_covariance(cond_selclass_features, dsm[split], num_workers=100, batch_size=512, pin_memory=True,\n",
    "                    cachefile=ef(f'{dataset}-{split}-layer{layernum}-condsel-mcov.npz'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, do a test pass over unseen (val set) examples, and measure average precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netdissect import pbar\n",
    "\n",
    "selected_classes = 500\n",
    "\n",
    "mcov.cuda_()\n",
    "selcov.to_('cuda')\n",
    "\n",
    "def logp_score(mcov, feat):\n",
    "    v = feat - mcov.mean()\n",
    "    b, _ = torch.lstsq(v.t(), mcov.covariance())\n",
    "    dot = -(v * b.t())\n",
    "    return dot.sum(1)\n",
    "\n",
    "# How much we think something is a member of one of the 500 seen claases\n",
    "def novelty_score(imgdat):\n",
    "    rep = model(imgdat.cuda(), layer=layernum)\n",
    "    bestscore = torch.cat([logp_score(selcov.conditional(cc), rep)[None,:]\n",
    "                           for cc in range(selected_classes)]).max(0)[0]\n",
    "    return logp_score(mcov, rep) - bestscore\n",
    "\n",
    "def batch_score_inliers(imgbatch, c):\n",
    "    selected = imgbatch[c < selected_classes]\n",
    "    if not len(selected):\n",
    "        return None\n",
    "    return novelty_score(selected)[:,None]\n",
    "\n",
    "def batch_score_outliers(imgbatch, c):\n",
    "    selected = imgbatch[c >= selected_classes]\n",
    "    if not len(selected):\n",
    "        return None\n",
    "    return novelty_score(selected)[:,None]\n",
    "\n",
    "rq_inlier = tally.tally_quantile(batch_score_inliers, dsv, num_workers=100, batch_size=512, pin_memory=True,\n",
    "                   cachefile=ef(f'{dataset}-{split}-layer{layernum}-bestof-sel{selected_classes}-inlier_rq.npz'))\n",
    "rq_outlier = tally.tally_quantile(batch_score_outliers, dsv, num_workers=100, batch_size=512, pin_memory=True,\n",
    "                   cachefile=ef(f'{dataset}-{split}-layer{layernum}-bestof-sel{selected_classes}-outlier_rq.npz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.title('Validation set scores')\n",
    "xrange = torch.linspace(0,1,100)\n",
    "plt.plot(rq_inlier.quantiles(xrange)[0].numpy(), xrange.numpy(), )\n",
    "plt.plot(rq_outlier.quantiles(xrange)[0].numpy(), xrange.numpy(), )\n",
    "plt.ylabel('percentile')\n",
    "plt.xlabel('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srange = torch.linspace(-75, 350, 100)\n",
    "true_pos = rq_inlier.normalize(srange[None])[0]\n",
    "false_pos = rq_outlier.normalize(srange[None])[0]\n",
    "precision = true_pos / (true_pos + false_pos + 1e-20)\n",
    "accuracy = (true_pos + (1 - false_pos)) / 2\n",
    "plt.title(\"multi-Gaussian model novelty detection using MoCo\\nFirst %d imagenet classes vs others\" % selected_classes)\n",
    "plt.plot(srange, true_pos, label=\"True positives\")\n",
    "plt.plot(srange, false_pos, label=\"False positives\")\n",
    "plt.plot(srange, precision, label=\"Precision\")\n",
    "plt.plot(srange, accuracy, label=\"Accuracy, max=%.3g\" % accuracy.max().item())\n",
    "plt.axhline(y=precision.mean(), color='g', linestyle='--', label=\"AP=%.3g\" % precision.mean().item())\n",
    "plt.xlabel('log score')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}